{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, 'utils')\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Multiply, Flatten, Concatenate, Dropout\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from process import *\n",
    "from utils import *\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = '01'\n",
    "\n",
    "dir_base = '~/CAD_120/data'\n",
    "dir_save = os.path.join('models')\n",
    "\n",
    "obj_list = load_words(os.path.join(dir_base, 'knowledge/object_list.txt'))\n",
    "attr_list = load_words(os.path.join(dir_base, 'knowledge/attribute_list.txt'))\n",
    "rel_list = load_words(os.path.join(dir_base, 'knowledge/relation_list.txt'))\n",
    "act_list = load_words(os.path.join(dir_base, 'knowledge/action_list.txt'))\n",
    "\n",
    "\n",
    "file_name_anno = os.path.join(dir_base, 'annotations/train/attr_'+list_id+'.json')\n",
    "dir_video = os.path.join('~/CAD_120/videos')\n",
    "\n",
    "with open(file_name_anno, 'r') as f:\n",
    "    data = json.load(f)    \n",
    "\n",
    "num_all = 0\n",
    "for attr in attr_list:\n",
    "    num_all = num_all+len(data[attr])\n",
    "    print (attr, len(data[attr]))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 30000\n",
    "\n",
    "data_anno = []\n",
    "class_weight = {}    \n",
    "for k in range(len(attr_list)):\n",
    "    attr = attr_list[k]\n",
    "    num = min(sample_num, len(data[attr]))\n",
    "    class_weight[k] = num_all/num    \n",
    "    print (attr, num)\n",
    "    \n",
    "    ids = list(range(0, len(data[attr])))\n",
    "    sample_ids = random.sample(ids, num)\n",
    "    for k in sample_ids:\n",
    "        data_anno.append(data[attr][k])\n",
    "\n",
    "    \n",
    "print ()\n",
    "print (class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_attr(vgg16, len_obj_list, len_attr_list, dropout = 0.5):\n",
    "\n",
    "    # appearance feature from vgg16 model\n",
    "    fc1_img = Dense(4096, activation = 'relu', name = 'fc1_img')(vgg16.layers[-4].output)\n",
    "    fc1_img = Dropout(dropout)(fc1_img)\n",
    "    fc2_img = Dense(4096, activation = 'relu', name = 'fc2_img')(fc1_img)\n",
    "    fc2_img = Dropout(dropout)(fc2_img)\n",
    "    \n",
    "    # feature selecttion with object label    \n",
    "    obj_label = Input(shape = (len_obj_list,))\n",
    "    fc1_obj = Dense(4096, activation = 'relu', name = 'fc1_obj')(obj_label)\n",
    "    fc1_obj = Dropout(dropout)(fc1_obj)\n",
    "    \n",
    "    # joint feature \n",
    "    fc_attr = Multiply()([fc1_obj, fc2_img])\n",
    "    fc_attr = Dropout(dropout)(fc_attr)\n",
    "    \n",
    "    prob_attr = Dense(len_attr_list, activation = 'softmax', name = 'prob_attr')(fc_attr)\n",
    "        \n",
    "    model_attr = Model(inputs = [obj_label, vgg16.input], outputs = prob_attr)\n",
    "       \n",
    "    # fix the convolutional layer\n",
    "    for layer in model_attr.layers[:20]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    \"\"\"\n",
    "    model_attr.summary()    \n",
    "    plot_model(model_attr, to_file='model.png')\n",
    "    \"\"\" \n",
    "    \n",
    "    return model_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "dropout = 0.5\n",
    "\n",
    "mtcnn_graph = tf.Graph()\n",
    "with mtcnn_graph.as_default():\n",
    "    gpu_option = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_option, allow_soft_placement=True))\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())     \n",
    "\n",
    "    vgg16 = VGG16(weights='imagenet')\n",
    "\n",
    "    model_attr = get_model_attr(vgg16, len(obj_list), len(attr_list), dropout)\n",
    "       \n",
    "    adam = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    model_attr.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    for epoch in range(epochs) :               \n",
    "        #train_data = sample_train_data_attr(data, attr_list, sample_num)\n",
    "        \n",
    "        train_data = []\n",
    "        ids = list(range(0, len(data_anno)))\n",
    "        random.shuffle(ids)\n",
    "        for k in ids:\n",
    "            train_data.append(data_anno[k])\n",
    "        \n",
    "        \n",
    "        batch_obj_label = np.empty([0, len(obj_list)])\n",
    "        batch_roi_img = np.empty([0, 224, 224, 3])\n",
    "        batch_attr_label = np.empty([0, len(attr_list)])    \n",
    "        \n",
    "        for k in range(len(train_data)):\n",
    "            person_id = train_data[k]['person_id']\n",
    "            video_label = train_data[k]['video_label']\n",
    "            video_id = train_data[k]['video_id']\n",
    "            obj_label = train_data[k]['obj_label']\n",
    "            frame_id = train_data[k]['frame_id']\n",
    "            roi = train_data[k]['roi']\n",
    "            attr_label = train_data[k]['attr_label']\n",
    "    \n",
    "            # get roi_img image\n",
    "            dir_img = os.path.join(dir_video, person_id, video_label, video_id)  \n",
    "            img = image.load_img(os.path.join(dir_img, 'RGB_' + str(frame_id + 1) + '.png'))\n",
    "                        \n",
    "            roi_img = get_roi_img(img, roi)            \n",
    "            obj_label = word2vec(obj_label, obj_list)\n",
    "            attr_label = word2vec(attr_label, attr_list)\n",
    "            \n",
    "            batch_obj_label = np.append(batch_obj_label, [obj_label], axis=0)\n",
    "            batch_roi_img = np.append(batch_roi_img, [roi_img], axis=0)\n",
    "            batch_attr_label = np.append(batch_attr_label, [attr_label], axis=0)\n",
    "            \n",
    "            if batch_obj_label.shape[0] == batch_size or k == len(train_data)-1:\n",
    "                train = model_attr.train_on_batch([batch_obj_label, batch_roi_img], batch_attr_label, \\\n",
    "                                                class_weight = class_weight)\n",
    "                            \n",
    "                print ('Epoch = '+str(epoch+1)+'/'+str(epochs)+\\\n",
    "                       ',  Progress = '+str(k+1)+'/'+str(len(train_data)), train)\n",
    "                                                                                                  \n",
    "                batch_obj_label = np.empty([0, len(obj_list)])\n",
    "                batch_roi_img = np.empty([0, 224, 224, 3])\n",
    "                batch_attr_label = np.empty([0, len(attr_list)])    \n",
    "       \n",
    "        model_save_name = os.path.join(dir_save, 'model_attr_'+list_id+'_'+str(epochs)+'.h5') \n",
    "        model_attr.save(model_save_name)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
