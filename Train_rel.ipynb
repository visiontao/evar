{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, 'utils')\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Multiply, Flatten, Concatenate, Dropout\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from process import *\n",
    "from utils import *\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "list_id = '01'\n",
    "\n",
    "dir_base = '~/CAD_120/data'\n",
    "dir_save = os.path.join('models')\n",
    "\n",
    "obj_list = load_words(os.path.join(dir_base, 'knowledge/object_list.txt'))\n",
    "attr_list = load_words(os.path.join(dir_base, 'knowledge/attribute_list.txt'))\n",
    "rel_list = load_words(os.path.join(dir_base, 'knowledge/relation_list.txt'))\n",
    "act_list = load_words(os.path.join(dir_base, 'knowledge/action_list.txt'))\n",
    "\n",
    "file_name_anno = os.path.join(dir_base, 'annotations/train/train_data_rel_'+list_id+'.json')\n",
    "dir_video = os.path.join('~/CAD_120/videos')\n",
    "\n",
    "with open(file_name_anno, 'r') as f:\n",
    "    data = json.load(f)    \n",
    "\n",
    "num_all = 0\n",
    "for rel in rel_list:\n",
    "    num_all = num_all+len(data[rel])\n",
    "    print (rel, len(data[rel])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 30000\n",
    "\n",
    "\n",
    "data_anno = []\n",
    "class_weight = {}    \n",
    "for k in range(len(rel_list)):\n",
    "    rel = rel_list[k]\n",
    "    num = min(sample_num, len(data[rel]))\n",
    "    class_weight[k] = num_all/num    \n",
    "        \n",
    "    print (rel, num)\n",
    "    \n",
    "    ids = list(range(0, len(data[rel])))\n",
    "    sample_ids = random.sample(ids, num)\n",
    "    for k in sample_ids:\n",
    "        data_anno.append(data[rel][k])\n",
    "\n",
    "    \n",
    "print ()\n",
    "print (class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_rel(vgg16, len_obj_list, len_rel_list, dropout = 0.5):\n",
    "    \n",
    "    # appearace feature from vgg16 model\n",
    "    fc1_img = Dense(4096, activation = 'relu', name = 'fc1_img')(vgg16.layers[-4].output)\n",
    "    fc1_img = Dropout(dropout)(fc1_img)\n",
    "    fc2_img = Dense(4096, activation = 'relu', name = 'fc2_img')(fc1_img)\n",
    "    fc2_img = Dropout(dropout)(fc2_img)\n",
    "    \n",
    "    # feature selection with object labels\n",
    "    sub_label = Input(shape = (len_obj_list,))\n",
    "    obj_label = Input(shape = (len_obj_list,))\n",
    "\n",
    "    obj_labels = Concatenate()([sub_label, obj_label])\n",
    "    fc1_obj = Dense(4096, activation = 'relu', name = 'fc1_obj')(obj_labels)\n",
    "    fc1_obj = Dropout(dropout)(fc1_obj)\n",
    "    \n",
    "    # joint feature\n",
    "    fc_rel = Multiply()([fc1_obj, fc2_img])\n",
    "    fc_rel = Dropout(dropout)(fc_rel)\n",
    "    \n",
    "    prob_rel = Dense(len_rel_list, activation='softmax', name = 'prob_rel')(fc_rel)\n",
    "\n",
    "    model_rel = Model(inputs = [sub_label, obj_label, vgg16.input], outputs = prob_rel)\n",
    "    \n",
    "    return model_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 1e-5\n",
    "dropout = 0.5\n",
    "\n",
    "mtcnn_graph = tf.Graph()\n",
    "with mtcnn_graph.as_default():\n",
    "    gpu_option = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_option, allow_soft_placement=True))\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())     \n",
    "\n",
    "    vgg16 = VGG16(weights='imagenet')\n",
    "\n",
    "    model_rel = get_model_rel(vgg16, len(obj_list), len(rel_list), dropout)\n",
    "    adam = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999)\n",
    "    model_rel.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    for epoch in range(epochs):        \n",
    "        \n",
    "        train_data = []\n",
    "        ids = list(range(0, len(data_anno)))\n",
    "        random.shuffle(ids)\n",
    "        for k in ids:\n",
    "            train_data.append(data_anno[k])\n",
    "        \n",
    "        \n",
    "        batch_sub_label = np.empty([0, len(obj_list)])\n",
    "        batch_obj_label = np.empty([0, len(obj_list)])\n",
    "        batch_union_img = np.empty([0, 224, 224, 3])\n",
    "        batch_rel_label = np.empty([0, len(rel_list)])    \n",
    "        \n",
    "        for k in range(len(train_data)):\n",
    "            person_id = train_data[k]['person_id']\n",
    "            video_label = train_data[k]['video_label']\n",
    "            video_id = train_data[k]['video_id']\n",
    "            obj_labels = train_data[k]['obj_labels']\n",
    "            frame_id = train_data[k]['frame_id']\n",
    "            rois = train_data[k]['rois']\n",
    "            rel_label = train_data[k]['rel_label']\n",
    "    \n",
    "            # get roi_img image\n",
    "            dir_img = os.path.join(dir_video, person_id, video_label, video_id)  \n",
    "            img = image.load_img(os.path.join(dir_img, 'RGB_' + str(frame_id + 1) + '.png'))\n",
    "            \n",
    "            union_img = get_union_img(img, rois, 5)         \n",
    "            sub_label = word2vec(obj_labels[0], obj_list)\n",
    "            obj_label = word2vec(obj_labels[1], obj_list)\n",
    "            rel_label = word2vec(rel_label, rel_list)\n",
    "            \n",
    "            batch_sub_label = np.append(batch_sub_label, [sub_label], axis=0)\n",
    "            batch_obj_label = np.append(batch_obj_label, [obj_label], axis=0)\n",
    "            batch_union_img = np.append(batch_union_img, [union_img], axis=0)\n",
    "            batch_rel_label = np.append(batch_rel_label, [rel_label], axis=0)\n",
    "            \n",
    "            if batch_sub_label.shape[0] == batch_size or k == len(train_data)-1:\n",
    "                train = model_rel.train_on_batch([batch_sub_label, batch_obj_label, batch_union_img], \\\n",
    "                                                 batch_rel_label, class_weight = class_weight)\n",
    "                            \n",
    "                print ('Epoch = '+str(epoch+1)+'/'+str(epochs)+\\\n",
    "                       ',  Progress = '+str(k+1)+'/'+str(len(train_data)), train)\n",
    "                                                                                                  \n",
    "                batch_sub_label = np.empty([0, len(obj_list)])\n",
    "                batch_obj_label = np.empty([0, len(obj_list)])\n",
    "                batch_union_img = np.empty([0, 224, 224, 3])\n",
    "                batch_rel_label = np.empty([0, len(rel_list)])    \n",
    "        \n",
    "        model_save_name = os.path.join(dir_save, 'model_rel_'+list_id+'_'+str(epochs)+'.h5') \n",
    "        model_rel.save(model_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
